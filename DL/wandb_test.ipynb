{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0e48de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:06:52.154221Z",
     "start_time": "2024-02-19T12:06:52.146740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (0.24.0)\n",
      "Requirement already satisfied: click>=8.0.1 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: eval-type-backport in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (0.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (3.1.46)\n",
      "Requirement already satisfied: packaging in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.15.0 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (6.33.0)\n",
      "Requirement already satisfied: pydantic<3 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (2.32.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (2.51.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jiawei-wang/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb\n",
    "!wandb login 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\n",
    "# ~/.netrc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc437c19-a95a-4491-b2a9-9cf59917571e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T14:08:33.203436Z",
     "iopub.status.busy": "2024-12-17T14:08:33.202778Z",
     "iopub.status.idle": "2024-12-17T14:08:33.225211Z",
     "shell.execute_reply": "2024-12-17T14:08:33.222790Z",
     "shell.execute_reply.started": "2024-12-17T14:08:33.203386Z"
    }
   },
   "source": [
    "```\n",
    "import wandb\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 1000\n",
    "NUM_TOKENS = 10\n",
    "LR = 1e-5\n",
    "KL_FACTOR = 6000\n",
    "WANDB = False\n",
    "\n",
    "if WANDB:\n",
    "    run = wandb.init(\n",
    "        project=\"tinycatstories\",\n",
    "        config={\n",
    "            \"epochs\": NUM_EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"num_tokens\": NUM_TOKENS,\n",
    "            \"learning_rate\": LR,\n",
    "            \"kl_factor\": KL_FACTOR,\n",
    "        },\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15111c13",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d730cc5-2000-4377-b9ac-c3da1ee69e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "print(wandb.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4c9871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:01:39.919238Z",
     "start_time": "2023-04-23T14:01:38.315799Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random # to set the python random seed\n",
    "import numpy # to set the numpy random seed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "from datetime import datetime\n",
    "# Ignore excessive warnings\n",
    "import logging\n",
    "logging.propagate = False \n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# WandB – Import the wandb library\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbfacf7",
   "metadata": {},
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b070f6",
   "metadata": {},
   "source": [
    "```\n",
    "!pip install wandb\n",
    "wandb login\n",
    "# api_key\n",
    "~/.netrc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d250d6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T12:20:22.753328Z",
     "start_time": "2023-04-23T12:20:22.747238Z"
    }
   },
   "source": [
    "- WandB: weights & biases\n",
    "\n",
    "```\n",
    "wandb.init(project=\"wandb-demo-0423\")\n",
    "# 字典（dict）\n",
    "config = wandb.config\n",
    "config[k] = v\n",
    "\n",
    "# 实例化模型\n",
    "model = Net().to(device)\n",
    "train_dataset\n",
    "test_dataset\n",
    "train_dataloader\n",
    "test_dataloader\n",
    "\n",
    "# 监控模型，histogram weights and biases\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_acc = train(model, train_dataloader)\n",
    "    # 字典的形式\n",
    "    wandb.log({\"train_loss\": train_loss, \"train_acc\": train_acc})\n",
    "    # 评估，不进行参数的更新\n",
    "    test_loss, test_acc = test(model, test_dataloader)\n",
    "    wandb.log({\"test_loss\": test_loss, \"test_acc\": train_acc})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda83126",
   "metadata": {},
   "source": [
    "## model, train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d1c2f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:01:46.208111Z",
     "start_time": "2023-04-23T14:01:46.203295Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, criterion, optimizer, device):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_batch = len(train_dataloader)\n",
    "    for batch_idx, (images, labels) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "\n",
    "        # 标准的处理，用 validate data；这个过程是监督训练过程，用于 early stop\n",
    "        n_corrects = (out.argmax(axis=1) == labels).sum().item()\n",
    "        acc = n_corrects/labels.size(0)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()   # 更细 模型参数\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += n_corrects\n",
    "        \n",
    "        if (batch_idx+1) % 200 == 0:\n",
    "            print(f'{datetime.now()}, {batch_idx+1}/{total_batch}: {loss.item():.4f}, acc: {acc}')\n",
    "    total_errors = len(train_dataloader.dataset) - total_correct\n",
    "    return total_loss, total_correct/len(train_dataloader.dataset), total_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7f0cdfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:03.797083Z",
     "start_time": "2023-04-23T14:02:03.784871Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def test(test_dataloader, model, criterion, device, classes):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    example_images = []\n",
    "    model.eval()\n",
    "    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1).to(device)\n",
    "    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1).to(device)\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        \n",
    "        mis_preds_indice = torch.flatten((preds != labels).nonzero())\n",
    "        mis_preds = preds[mis_preds_indice]\n",
    "        mis_labels = labels[mis_preds_indice]\n",
    "        mis_images = images[mis_preds_indice]\n",
    "        \n",
    "        # 13*8 + 4 == 108\n",
    "        for idx in range(len(mis_preds)):\n",
    "            if len(example_images) < 32: \n",
    "                        \n",
    "                        # --- 关键修改：反归一化 ---\n",
    "                        img = images[idx] * std + mean # 变回 [0, 1] 范围\n",
    "                        img = img.clamp(0, 1)          # 强制截断，防止溢出导致的噪点\n",
    "                        \n",
    "                        # --- 关键修改：维度转换 (C, H, W) -> (H, W, C) ---\n",
    "                        img_np = img.cpu().numpy().transpose(1, 2, 0)\n",
    "                        \n",
    "                        # 3. 转换为 uint8 [0, 255]（这是最保险的格式）\n",
    "                        img_uint8 = (img_np * 255).astype(np.uint8)\n",
    "                        \n",
    "                        example_images.append(wandb.Image(\n",
    "                            img_uint8, \n",
    "                            caption=f\"Pred: {classes[preds[idx]]}, Truth: {classes[labels[idx]]}\"\n",
    "                        ))\n",
    "            else:\n",
    "                break\n",
    "    total_errors = len(test_loader.dataset) - total_correct\n",
    "    return example_images, total_loss, total_correct / len(test_loader.dataset), total_errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e4bf47",
   "metadata": {},
   "source": [
    "## wandb config & dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20354ff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:15.849162Z",
     "start_time": "2023-04-23T14:02:05.682841Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/jiawei-wang/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjw4807\u001b[0m (\u001b[33mlione-wang\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jiawei-wang/workspace/Lab/DL/wandb/run-20260129_130650-z7mn4jfu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lione-wang/Lab-DL/runs/z7mn4jfu' target=\"_blank\">vital-planet-5</a></strong> to <a href='https://wandb.ai/lione-wang/Lab-DL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lione-wang/Lab-DL' target=\"_blank\">https://wandb.ai/lione-wang/Lab-DL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lione-wang/Lab-DL/runs/z7mn4jfu' target=\"_blank\">https://wandb.ai/lione-wang/Lab-DL/runs/z7mn4jfu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"WANDB_API_KEY\"] = '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'\n",
    "os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "\n",
    "# WandB – Initialize a new run\n",
    "# 一个 project 可以 run 多次\n",
    "wandb.init(project=\"Lab-DL\")\n",
    "wandb.watch_called = False # Re-run the model without restarting the runtime, unnecessary after our next release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d130c023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:17.680506Z",
     "start_time": "2023-04-23T14:02:17.673655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty dict\n",
    "wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac35385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:18.655123Z",
     "start_time": "2023-04-23T14:02:18.641752Z"
    }
   },
   "outputs": [],
   "source": [
    "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
    "config = wandb.config          # Initialize config\n",
    "config.batch_size = 64          # input batch size for training (default: 64)\n",
    "config.test_batch_size = 32    # input batch size for testing (default: 1000)\n",
    "config.epochs = 30             # number of epochs to train (default: 10)\n",
    "config.lr = 1e-3              # learning rate (default: 0.01)\n",
    "config.momentum = 0.9         # SGD momentum (default: 0.5) \n",
    "config.weight_decay = 5e-4\n",
    "config.no_cuda = False         # disables CUDA training\n",
    "config.seed = 42               # random seed (default: 42)\n",
    "config.log_interval = 10     # how many batches to wait before logging training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30148831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:10:30.432096Z",
     "start_time": "2023-04-23T15:10:30.423172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "{'num_workers': 1, 'pin_memory': True}\n"
     ]
    }
   ],
   "source": [
    "use_cuda = not config.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c289c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:24.799152Z",
     "start_time": "2023-04-23T14:02:22.592645Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bba03e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:26.754527Z",
     "start_time": "2023-04-23T14:02:24.801556Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "    \n",
    "# Now we load our training and test datasets and apply the transformations defined above\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                 download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=config.batch_size,\n",
    "                                           shuffle=True, \n",
    "                                           **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size=config.test_batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          **kwargs)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "635db4d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:11:21.290317Z",
     "start_time": "2023-04-23T15:11:21.283595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "781\n",
      "782\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(train_dataset)//config.batch_size)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c2e26f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:11:50.081828Z",
     "start_time": "2023-04-23T15:11:50.069920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "312\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataset))\n",
    "print(len(test_dataset)//config.test_batch_size)\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba878c",
   "metadata": {},
   "source": [
    "## training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99a696a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:52:50.016509Z",
     "start_time": "2023-04-23T14:02:30.904713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-29 13:13:14.132820, 200/782: 1.0483, acc: 0.6875\n",
      "2026-01-29 13:13:23.292310, 400/782: 1.1377, acc: 0.625\n",
      "2026-01-29 13:13:32.437868, 600/782: 1.1427, acc: 0.5625\n",
      "\n",
      "2026-01-29 13:13:48.737307, epoch: 1, train_loss: 843.1986, train_acc: 0.61, test_loss: 329.1142, test_acc: 0.62\n",
      "\n",
      "2026-01-29 13:13:58.131501, 200/782: 0.9349, acc: 0.640625\n",
      "2026-01-29 13:14:07.450962, 400/782: 1.3221, acc: 0.515625\n",
      "2026-01-29 13:14:16.778518, 600/782: 0.9524, acc: 0.703125\n",
      "\n",
      "2026-01-29 13:14:32.843156, epoch: 2, train_loss: 769.8788, train_acc: 0.65, test_loss: 314.0742, test_acc: 0.65\n",
      "\n",
      "2026-01-29 13:14:42.141791, 200/782: 0.9358, acc: 0.6875\n",
      "2026-01-29 13:14:51.352657, 400/782: 0.8662, acc: 0.65625\n",
      "2026-01-29 13:15:00.556041, 600/782: 0.8683, acc: 0.65625\n",
      "\n",
      "2026-01-29 13:15:16.633403, epoch: 3, train_loss: 691.4147, train_acc: 0.68, test_loss: 295.2364, test_acc: 0.66\n",
      "\n",
      "2026-01-29 13:15:25.964212, 200/782: 0.8586, acc: 0.640625\n",
      "2026-01-29 13:15:35.170838, 400/782: 0.5662, acc: 0.765625\n",
      "2026-01-29 13:15:44.304793, 600/782: 0.8040, acc: 0.640625\n",
      "\n",
      "2026-01-29 13:16:00.365702, epoch: 4, train_loss: 636.8208, train_acc: 0.71, test_loss: 264.2282, test_acc: 0.70\n",
      "\n",
      "2026-01-29 13:16:09.775514, 200/782: 0.5936, acc: 0.828125\n",
      "2026-01-29 13:16:18.996125, 400/782: 0.6085, acc: 0.78125\n",
      "2026-01-29 13:16:28.195099, 600/782: 1.0876, acc: 0.65625\n",
      "\n",
      "2026-01-29 13:16:44.272443, epoch: 5, train_loss: 584.9225, train_acc: 0.74, test_loss: 265.8423, test_acc: 0.70\n",
      "\n",
      "2026-01-29 13:16:53.632447, 200/782: 0.8561, acc: 0.65625\n",
      "2026-01-29 13:17:02.778568, 400/782: 0.7328, acc: 0.703125\n",
      "2026-01-29 13:17:12.015959, 600/782: 0.7475, acc: 0.71875\n",
      "\n",
      "2026-01-29 13:17:28.126447, epoch: 6, train_loss: 537.4288, train_acc: 0.76, test_loss: 241.2791, test_acc: 0.73\n",
      "\n",
      "2026-01-29 13:17:37.484944, 200/782: 0.5816, acc: 0.796875\n",
      "2026-01-29 13:17:46.601158, 400/782: 0.5249, acc: 0.828125\n",
      "2026-01-29 13:17:55.860979, 600/782: 0.5596, acc: 0.796875\n",
      "\n",
      "2026-01-29 13:18:12.020022, epoch: 7, train_loss: 491.7988, train_acc: 0.78, test_loss: 263.6806, test_acc: 0.71\n",
      "\n",
      "2026-01-29 13:18:21.421847, 200/782: 0.6619, acc: 0.765625\n",
      "2026-01-29 13:18:30.753006, 400/782: 0.4467, acc: 0.875\n",
      "2026-01-29 13:18:40.044516, 600/782: 0.4841, acc: 0.828125\n",
      "\n",
      "2026-01-29 13:18:56.229724, epoch: 8, train_loss: 457.6748, train_acc: 0.79, test_loss: 234.6593, test_acc: 0.74\n",
      "\n",
      "2026-01-29 13:19:05.552253, 200/782: 0.6315, acc: 0.75\n",
      "2026-01-29 13:19:14.809752, 400/782: 0.6417, acc: 0.78125\n",
      "2026-01-29 13:19:23.978695, 600/782: 0.4663, acc: 0.828125\n",
      "\n",
      "2026-01-29 13:19:40.085204, epoch: 9, train_loss: 411.8649, train_acc: 0.81, test_loss: 233.4893, test_acc: 0.74\n",
      "\n",
      "2026-01-29 13:19:49.438244, 200/782: 0.4646, acc: 0.78125\n",
      "2026-01-29 13:19:58.715675, 400/782: 0.7371, acc: 0.71875\n",
      "2026-01-29 13:20:07.947992, 600/782: 0.6111, acc: 0.765625\n",
      "\n",
      "2026-01-29 13:20:24.019116, epoch: 10, train_loss: 369.5795, train_acc: 0.83, test_loss: 244.0064, test_acc: 0.73\n",
      "\n",
      "2026-01-29 13:20:33.344212, 200/782: 0.3184, acc: 0.859375\n",
      "2026-01-29 13:20:42.617958, 400/782: 0.6887, acc: 0.765625\n",
      "2026-01-29 13:20:51.841183, 600/782: 0.3295, acc: 0.890625\n",
      "\n",
      "2026-01-29 13:21:07.943337, epoch: 11, train_loss: 322.8835, train_acc: 0.85, test_loss: 240.4244, test_acc: 0.75\n",
      "\n",
      "2026-01-29 13:21:17.308172, 200/782: 0.3077, acc: 0.921875\n",
      "2026-01-29 13:21:26.514503, 400/782: 0.4845, acc: 0.8125\n",
      "2026-01-29 13:21:35.667976, 600/782: 0.4982, acc: 0.859375\n",
      "\n",
      "2026-01-29 13:21:51.717193, epoch: 12, train_loss: 286.1654, train_acc: 0.87, test_loss: 213.7559, test_acc: 0.77\n",
      "\n",
      "2026-01-29 13:22:01.046421, 200/782: 0.1913, acc: 0.921875\n",
      "2026-01-29 13:22:10.232174, 400/782: 0.4439, acc: 0.828125\n",
      "2026-01-29 13:22:19.399275, 600/782: 0.2993, acc: 0.890625\n",
      "\n",
      "2026-01-29 13:22:35.472755, epoch: 13, train_loss: 259.2782, train_acc: 0.88, test_loss: 217.7321, test_acc: 0.77\n",
      "\n",
      "2026-01-29 13:22:44.811204, 200/782: 0.3172, acc: 0.90625\n",
      "2026-01-29 13:22:53.944363, 400/782: 0.1256, acc: 0.96875\n",
      "2026-01-29 13:23:03.166827, 600/782: 0.1878, acc: 0.96875\n",
      "\n",
      "2026-01-29 13:23:19.197096, epoch: 14, train_loss: 205.3200, train_acc: 0.91, test_loss: 232.9525, test_acc: 0.78\n",
      "\n",
      "2026-01-29 13:23:28.547833, 200/782: 0.3903, acc: 0.828125\n",
      "2026-01-29 13:23:37.741413, 400/782: 0.2052, acc: 0.890625\n",
      "2026-01-29 13:23:46.920576, 600/782: 0.2783, acc: 0.90625\n",
      "\n",
      "2026-01-29 13:24:02.974402, epoch: 15, train_loss: 177.3086, train_acc: 0.92, test_loss: 265.6153, test_acc: 0.75\n",
      "\n",
      "2026-01-29 13:24:12.289995, 200/782: 0.1161, acc: 0.96875\n",
      "2026-01-29 13:24:21.523833, 400/782: 0.2110, acc: 0.921875\n",
      "2026-01-29 13:24:30.714110, 600/782: 0.1048, acc: 0.96875\n",
      "\n",
      "2026-01-29 13:24:46.737604, epoch: 16, train_loss: 142.5910, train_acc: 0.94, test_loss: 267.8213, test_acc: 0.78\n",
      "\n",
      "2026-01-29 13:24:56.073278, 200/782: 0.3717, acc: 0.875\n",
      "2026-01-29 13:25:05.197451, 400/782: 0.1578, acc: 0.9375\n",
      "2026-01-29 13:25:14.408047, 600/782: 0.1701, acc: 0.953125\n",
      "\n",
      "2026-01-29 13:25:30.461041, epoch: 17, train_loss: 135.8292, train_acc: 0.94, test_loss: 243.2161, test_acc: 0.78\n",
      "\n",
      "2026-01-29 13:25:39.788666, 200/782: 0.1866, acc: 0.90625\n",
      "2026-01-29 13:25:49.048316, 400/782: 0.0536, acc: 0.984375\n",
      "2026-01-29 13:25:58.266932, 600/782: 0.1688, acc: 0.90625\n",
      "\n",
      "2026-01-29 13:26:14.367614, epoch: 18, train_loss: 98.1129, train_acc: 0.96, test_loss: 225.8120, test_acc: 0.79\n",
      "\n",
      "2026-01-29 13:26:23.615297, 200/782: 0.0337, acc: 0.984375\n",
      "2026-01-29 13:26:32.838638, 400/782: 0.0935, acc: 0.96875\n",
      "2026-01-29 13:26:42.028372, 600/782: 0.0624, acc: 0.984375\n",
      "\n",
      "2026-01-29 13:26:58.068810, epoch: 19, train_loss: 76.6566, train_acc: 0.97, test_loss: 327.5595, test_acc: 0.75\n",
      "\n",
      "2026-01-29 13:27:07.381042, 200/782: 0.0904, acc: 0.953125\n",
      "2026-01-29 13:27:16.513445, 400/782: 0.1321, acc: 0.9375\n",
      "2026-01-29 13:27:25.776657, 600/782: 0.2151, acc: 0.90625\n",
      "\n",
      "2026-01-29 13:27:41.831013, epoch: 20, train_loss: 75.4975, train_acc: 0.97, test_loss: 327.8731, test_acc: 0.77\n",
      "\n",
      "2026-01-29 13:27:51.163890, 200/782: 0.0156, acc: 1.0\n",
      "2026-01-29 13:28:00.454538, 400/782: 0.1453, acc: 0.9375\n",
      "2026-01-29 13:28:09.700648, 600/782: 0.0645, acc: 1.0\n",
      "\n",
      "2026-01-29 13:28:25.630644, epoch: 21, train_loss: 53.5688, train_acc: 0.98, test_loss: 289.1563, test_acc: 0.78\n",
      "\n",
      "2026-01-29 13:28:34.988131, 200/782: 0.0253, acc: 0.984375\n",
      "2026-01-29 13:28:44.211726, 400/782: 0.1095, acc: 0.96875\n",
      "2026-01-29 13:28:53.441583, 600/782: 0.1160, acc: 0.953125\n",
      "\n",
      "2026-01-29 13:29:09.513500, epoch: 22, train_loss: 47.6772, train_acc: 0.98, test_loss: 287.5264, test_acc: 0.79\n",
      "\n",
      "2026-01-29 13:29:18.809268, 200/782: 0.0619, acc: 0.96875\n",
      "2026-01-29 13:29:27.994501, 400/782: 0.0180, acc: 1.0\n",
      "2026-01-29 13:29:37.223691, 600/782: 0.4057, acc: 0.890625\n",
      "\n",
      "2026-01-29 13:29:53.218380, epoch: 23, train_loss: 46.2190, train_acc: 0.98, test_loss: 297.0941, test_acc: 0.80\n",
      "\n",
      "2026-01-29 13:30:02.703705, 200/782: 0.0086, acc: 1.0\n",
      "2026-01-29 13:30:12.048927, 400/782: 0.0552, acc: 0.984375\n",
      "2026-01-29 13:30:21.366569, 600/782: 0.0086, acc: 1.0\n",
      "\n",
      "2026-01-29 13:30:37.516426, epoch: 24, train_loss: 30.0381, train_acc: 0.99, test_loss: 286.4873, test_acc: 0.80\n",
      "\n",
      "2026-01-29 13:30:46.879544, 200/782: 0.0106, acc: 1.0\n",
      "2026-01-29 13:30:56.099662, 400/782: 0.0527, acc: 0.984375\n",
      "2026-01-29 13:31:05.307131, 600/782: 0.0241, acc: 0.984375\n",
      "\n",
      "2026-01-29 13:31:21.439201, epoch: 25, train_loss: 27.6908, train_acc: 0.99, test_loss: 295.7622, test_acc: 0.78\n",
      "\n",
      "2026-01-29 13:31:30.791746, 200/782: 0.0078, acc: 1.0\n",
      "2026-01-29 13:31:39.998515, 400/782: 0.0066, acc: 1.0\n",
      "2026-01-29 13:31:49.157697, 600/782: 0.0885, acc: 0.984375\n",
      "\n",
      "2026-01-29 13:32:05.346404, epoch: 26, train_loss: 32.3394, train_acc: 0.99, test_loss: 319.2618, test_acc: 0.79\n",
      "\n",
      "2026-01-29 13:32:14.775367, 200/782: 0.0044, acc: 1.0\n",
      "2026-01-29 13:32:24.030148, 400/782: 0.0208, acc: 0.984375\n",
      "2026-01-29 13:32:33.408540, 600/782: 0.0016, acc: 1.0\n",
      "\n",
      "2026-01-29 13:32:49.548202, epoch: 27, train_loss: 8.4749, train_acc: 1.00, test_loss: 322.3104, test_acc: 0.81\n",
      "\n",
      "2026-01-29 13:32:58.879733, 200/782: 0.0018, acc: 1.0\n",
      "2026-01-29 13:33:08.025089, 400/782: 0.0626, acc: 0.984375\n",
      "2026-01-29 13:33:17.259295, 600/782: 0.0074, acc: 1.0\n",
      "\n",
      "2026-01-29 13:33:33.345494, epoch: 28, train_loss: 18.8972, train_acc: 0.99, test_loss: 277.5366, test_acc: 0.80\n",
      "\n",
      "2026-01-29 13:33:42.644108, 200/782: 0.0019, acc: 1.0\n",
      "2026-01-29 13:33:51.943105, 400/782: 0.0142, acc: 1.0\n",
      "2026-01-29 13:34:01.170982, 600/782: 0.0017, acc: 1.0\n",
      "\n",
      "2026-01-29 13:34:17.311327, epoch: 29, train_loss: 9.4119, train_acc: 1.00, test_loss: 343.2547, test_acc: 0.77\n",
      "\n",
      "2026-01-29 13:34:26.582122, 200/782: 0.0051, acc: 1.0\n",
      "2026-01-29 13:34:35.831603, 400/782: 0.0017, acc: 1.0\n",
      "2026-01-29 13:34:45.076042, 600/782: 0.0015, acc: 1.0\n",
      "\n",
      "2026-01-29 13:35:01.140685, epoch: 30, train_loss: 8.3551, train_acc: 1.00, test_loss: 442.0490, test_acc: 0.77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set random seeds and deterministic pytorch for reproducibility\n",
    "# random.seed(config.seed)      \n",
    "torch.manual_seed(config.seed) \n",
    "# numpy.random.seed(config.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Load the dataset: We're training our CNN on CIFAR10 (https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# WandB – wandb.watch() automatically fetches all layer dimensions, gradients, model parameters and logs them automatically to your dashboard.\n",
    "# Using log=\"all\" log histograms of parameter values in addition to gradients\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "for epoch in range(1, config.epochs + 1):\n",
    "    train_loss, train_acc, train_errors = train(train_loader, model, criterion, optimizer, device)\n",
    "    #字典的形式放在wandb的log里\n",
    "    wandb.log({\"train_loss\": train_loss, \"train_acc\": train_acc, \"train_errors\": train_errors})\n",
    "    example_images, test_loss, test_acc, test_errors = test(test_loader, model, criterion, device, classes)\n",
    "    wandb.log({'example_images': example_images, 'test_loss': test_loss, 'test_acc': test_acc, 'test_errors': test_errors})\n",
    "    print()\n",
    "    print(f'{datetime.now()}, epoch: {epoch}, train_loss: {train_loss:.4f}, train_acc: {train_acc:.2f}, test_loss: {test_loss:.4f}, test_acc: {test_acc:.2f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "333f99ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/jiawei-wang/workspace/Lab/DL/wandb/run-20260129_130650-z7mn4jfu/files/model.ckpt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WandB – Save the model checkpoint. This automatically saves a file to the cloud and associates it with the current run.\n",
    "torch.save(model.state_dict(), \"model.ckpt\")\n",
    "wandb.save('model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ubuntu-5070Ti",
   "language": "python",
   "name": "rdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
