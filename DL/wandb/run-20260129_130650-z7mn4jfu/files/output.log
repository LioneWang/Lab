cuda
{'num_workers': 1, 'pin_memory': True}
/home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
50000
781
782
10000
312
313
2026-01-29 13:08:21.493956, 200/782: 1.7288, acc: 0.34375
2026-01-29 13:08:30.619984, 400/782: 1.5819, acc: 0.453125
2026-01-29 13:08:39.798412, 600/782: 1.6957, acc: 0.34375
2026-01-29 13:09:39.132841, 200/782: 1.4635, acc: 0.546875
2026-01-29 13:09:48.546310, 400/782: 1.4243, acc: 0.46875
2026-01-29 13:09:57.727774, 600/782: 1.4737, acc: 0.5
2026-01-29 13:11:44.426523, 200/782: 1.2600, acc: 0.546875
2026-01-29 13:11:53.663225, 400/782: 1.2920, acc: 0.53125
2026-01-29 13:12:02.845645, 600/782: 1.3247, acc: 0.53125
2026-01-29 13:13:14.132820, 200/782: 1.0483, acc: 0.6875
2026-01-29 13:13:23.292310, 400/782: 1.1377, acc: 0.625
2026-01-29 13:13:32.437868, 600/782: 1.1427, acc: 0.5625

2026-01-29 13:13:48.737307, epoch: 1, train_loss: 843.1986, train_acc: 0.61, test_loss: 329.1142, test_acc: 0.62

2026-01-29 13:13:58.131501, 200/782: 0.9349, acc: 0.640625
2026-01-29 13:14:07.450962, 400/782: 1.3221, acc: 0.515625
2026-01-29 13:14:16.778518, 600/782: 0.9524, acc: 0.703125

2026-01-29 13:14:32.843156, epoch: 2, train_loss: 769.8788, train_acc: 0.65, test_loss: 314.0742, test_acc: 0.65

2026-01-29 13:14:42.141791, 200/782: 0.9358, acc: 0.6875
2026-01-29 13:14:51.352657, 400/782: 0.8662, acc: 0.65625
2026-01-29 13:15:00.556041, 600/782: 0.8683, acc: 0.65625

2026-01-29 13:15:16.633403, epoch: 3, train_loss: 691.4147, train_acc: 0.68, test_loss: 295.2364, test_acc: 0.66

2026-01-29 13:15:25.964212, 200/782: 0.8586, acc: 0.640625
2026-01-29 13:15:35.170838, 400/782: 0.5662, acc: 0.765625
2026-01-29 13:15:44.304793, 600/782: 0.8040, acc: 0.640625

2026-01-29 13:16:00.365702, epoch: 4, train_loss: 636.8208, train_acc: 0.71, test_loss: 264.2282, test_acc: 0.70

2026-01-29 13:16:09.775514, 200/782: 0.5936, acc: 0.828125
2026-01-29 13:16:18.996125, 400/782: 0.6085, acc: 0.78125
2026-01-29 13:16:28.195099, 600/782: 1.0876, acc: 0.65625

2026-01-29 13:16:44.272443, epoch: 5, train_loss: 584.9225, train_acc: 0.74, test_loss: 265.8423, test_acc: 0.70

2026-01-29 13:16:53.632447, 200/782: 0.8561, acc: 0.65625
2026-01-29 13:17:02.778568, 400/782: 0.7328, acc: 0.703125
2026-01-29 13:17:12.015959, 600/782: 0.7475, acc: 0.71875

2026-01-29 13:17:28.126447, epoch: 6, train_loss: 537.4288, train_acc: 0.76, test_loss: 241.2791, test_acc: 0.73

2026-01-29 13:17:37.484944, 200/782: 0.5816, acc: 0.796875
2026-01-29 13:17:46.601158, 400/782: 0.5249, acc: 0.828125
2026-01-29 13:17:55.860979, 600/782: 0.5596, acc: 0.796875

2026-01-29 13:18:12.020022, epoch: 7, train_loss: 491.7988, train_acc: 0.78, test_loss: 263.6806, test_acc: 0.71

2026-01-29 13:18:21.421847, 200/782: 0.6619, acc: 0.765625
2026-01-29 13:18:30.753006, 400/782: 0.4467, acc: 0.875
2026-01-29 13:18:40.044516, 600/782: 0.4841, acc: 0.828125

2026-01-29 13:18:56.229724, epoch: 8, train_loss: 457.6748, train_acc: 0.79, test_loss: 234.6593, test_acc: 0.74

2026-01-29 13:19:05.552253, 200/782: 0.6315, acc: 0.75
2026-01-29 13:19:14.809752, 400/782: 0.6417, acc: 0.78125
2026-01-29 13:19:23.978695, 600/782: 0.4663, acc: 0.828125

2026-01-29 13:19:40.085204, epoch: 9, train_loss: 411.8649, train_acc: 0.81, test_loss: 233.4893, test_acc: 0.74

2026-01-29 13:19:49.438244, 200/782: 0.4646, acc: 0.78125
2026-01-29 13:19:58.715675, 400/782: 0.7371, acc: 0.71875
2026-01-29 13:20:07.947992, 600/782: 0.6111, acc: 0.765625

2026-01-29 13:20:24.019116, epoch: 10, train_loss: 369.5795, train_acc: 0.83, test_loss: 244.0064, test_acc: 0.73

2026-01-29 13:20:33.344212, 200/782: 0.3184, acc: 0.859375
2026-01-29 13:20:42.617958, 400/782: 0.6887, acc: 0.765625
2026-01-29 13:20:51.841183, 600/782: 0.3295, acc: 0.890625

2026-01-29 13:21:07.943337, epoch: 11, train_loss: 322.8835, train_acc: 0.85, test_loss: 240.4244, test_acc: 0.75

2026-01-29 13:21:17.308172, 200/782: 0.3077, acc: 0.921875
2026-01-29 13:21:26.514503, 400/782: 0.4845, acc: 0.8125
2026-01-29 13:21:35.667976, 600/782: 0.4982, acc: 0.859375

2026-01-29 13:21:51.717193, epoch: 12, train_loss: 286.1654, train_acc: 0.87, test_loss: 213.7559, test_acc: 0.77

2026-01-29 13:22:01.046421, 200/782: 0.1913, acc: 0.921875
2026-01-29 13:22:10.232174, 400/782: 0.4439, acc: 0.828125
2026-01-29 13:22:19.399275, 600/782: 0.2993, acc: 0.890625

2026-01-29 13:22:35.472755, epoch: 13, train_loss: 259.2782, train_acc: 0.88, test_loss: 217.7321, test_acc: 0.77

2026-01-29 13:22:44.811204, 200/782: 0.3172, acc: 0.90625
2026-01-29 13:22:53.944363, 400/782: 0.1256, acc: 0.96875
2026-01-29 13:23:03.166827, 600/782: 0.1878, acc: 0.96875

2026-01-29 13:23:19.197096, epoch: 14, train_loss: 205.3200, train_acc: 0.91, test_loss: 232.9525, test_acc: 0.78

2026-01-29 13:23:28.547833, 200/782: 0.3903, acc: 0.828125
2026-01-29 13:23:37.741413, 400/782: 0.2052, acc: 0.890625
2026-01-29 13:23:46.920576, 600/782: 0.2783, acc: 0.90625

2026-01-29 13:24:02.974402, epoch: 15, train_loss: 177.3086, train_acc: 0.92, test_loss: 265.6153, test_acc: 0.75

2026-01-29 13:24:12.289995, 200/782: 0.1161, acc: 0.96875
2026-01-29 13:24:21.523833, 400/782: 0.2110, acc: 0.921875
2026-01-29 13:24:30.714110, 600/782: 0.1048, acc: 0.96875

2026-01-29 13:24:46.737604, epoch: 16, train_loss: 142.5910, train_acc: 0.94, test_loss: 267.8213, test_acc: 0.78

2026-01-29 13:24:56.073278, 200/782: 0.3717, acc: 0.875
2026-01-29 13:25:05.197451, 400/782: 0.1578, acc: 0.9375
2026-01-29 13:25:14.408047, 600/782: 0.1701, acc: 0.953125

2026-01-29 13:25:30.461041, epoch: 17, train_loss: 135.8292, train_acc: 0.94, test_loss: 243.2161, test_acc: 0.78

2026-01-29 13:25:39.788666, 200/782: 0.1866, acc: 0.90625
2026-01-29 13:25:49.048316, 400/782: 0.0536, acc: 0.984375
2026-01-29 13:25:58.266932, 600/782: 0.1688, acc: 0.90625

2026-01-29 13:26:14.367614, epoch: 18, train_loss: 98.1129, train_acc: 0.96, test_loss: 225.8120, test_acc: 0.79

2026-01-29 13:26:23.615297, 200/782: 0.0337, acc: 0.984375
2026-01-29 13:26:32.838638, 400/782: 0.0935, acc: 0.96875
2026-01-29 13:26:42.028372, 600/782: 0.0624, acc: 0.984375

2026-01-29 13:26:58.068810, epoch: 19, train_loss: 76.6566, train_acc: 0.97, test_loss: 327.5595, test_acc: 0.75

2026-01-29 13:27:07.381042, 200/782: 0.0904, acc: 0.953125
2026-01-29 13:27:16.513445, 400/782: 0.1321, acc: 0.9375
2026-01-29 13:27:25.776657, 600/782: 0.2151, acc: 0.90625

2026-01-29 13:27:41.831013, epoch: 20, train_loss: 75.4975, train_acc: 0.97, test_loss: 327.8731, test_acc: 0.77

2026-01-29 13:27:51.163890, 200/782: 0.0156, acc: 1.0
2026-01-29 13:28:00.454538, 400/782: 0.1453, acc: 0.9375
2026-01-29 13:28:09.700648, 600/782: 0.0645, acc: 1.0

2026-01-29 13:28:25.630644, epoch: 21, train_loss: 53.5688, train_acc: 0.98, test_loss: 289.1563, test_acc: 0.78

2026-01-29 13:28:34.988131, 200/782: 0.0253, acc: 0.984375
2026-01-29 13:28:44.211726, 400/782: 0.1095, acc: 0.96875
2026-01-29 13:28:53.441583, 600/782: 0.1160, acc: 0.953125

2026-01-29 13:29:09.513500, epoch: 22, train_loss: 47.6772, train_acc: 0.98, test_loss: 287.5264, test_acc: 0.79

2026-01-29 13:29:18.809268, 200/782: 0.0619, acc: 0.96875
2026-01-29 13:29:27.994501, 400/782: 0.0180, acc: 1.0
2026-01-29 13:29:37.223691, 600/782: 0.4057, acc: 0.890625

2026-01-29 13:29:53.218380, epoch: 23, train_loss: 46.2190, train_acc: 0.98, test_loss: 297.0941, test_acc: 0.80

2026-01-29 13:30:02.703705, 200/782: 0.0086, acc: 1.0
2026-01-29 13:30:12.048927, 400/782: 0.0552, acc: 0.984375
2026-01-29 13:30:21.366569, 600/782: 0.0086, acc: 1.0

2026-01-29 13:30:37.516426, epoch: 24, train_loss: 30.0381, train_acc: 0.99, test_loss: 286.4873, test_acc: 0.80

2026-01-29 13:30:46.879544, 200/782: 0.0106, acc: 1.0
2026-01-29 13:30:56.099662, 400/782: 0.0527, acc: 0.984375
2026-01-29 13:31:05.307131, 600/782: 0.0241, acc: 0.984375

2026-01-29 13:31:21.439201, epoch: 25, train_loss: 27.6908, train_acc: 0.99, test_loss: 295.7622, test_acc: 0.78

2026-01-29 13:31:30.791746, 200/782: 0.0078, acc: 1.0
2026-01-29 13:31:39.998515, 400/782: 0.0066, acc: 1.0
2026-01-29 13:31:49.157697, 600/782: 0.0885, acc: 0.984375

2026-01-29 13:32:05.346404, epoch: 26, train_loss: 32.3394, train_acc: 0.99, test_loss: 319.2618, test_acc: 0.79

2026-01-29 13:32:14.775367, 200/782: 0.0044, acc: 1.0
2026-01-29 13:32:24.030148, 400/782: 0.0208, acc: 0.984375
2026-01-29 13:32:33.408540, 600/782: 0.0016, acc: 1.0

2026-01-29 13:32:49.548202, epoch: 27, train_loss: 8.4749, train_acc: 1.00, test_loss: 322.3104, test_acc: 0.81

2026-01-29 13:32:58.879733, 200/782: 0.0018, acc: 1.0
2026-01-29 13:33:08.025089, 400/782: 0.0626, acc: 0.984375
2026-01-29 13:33:17.259295, 600/782: 0.0074, acc: 1.0

2026-01-29 13:33:33.345494, epoch: 28, train_loss: 18.8972, train_acc: 0.99, test_loss: 277.5366, test_acc: 0.80

2026-01-29 13:33:42.644108, 200/782: 0.0019, acc: 1.0
2026-01-29 13:33:51.943105, 400/782: 0.0142, acc: 1.0
2026-01-29 13:34:01.170982, 600/782: 0.0017, acc: 1.0

2026-01-29 13:34:17.311327, epoch: 29, train_loss: 9.4119, train_acc: 1.00, test_loss: 343.2547, test_acc: 0.77

2026-01-29 13:34:26.582122, 200/782: 0.0051, acc: 1.0
2026-01-29 13:34:35.831603, 400/782: 0.0017, acc: 1.0
2026-01-29 13:34:45.076042, 600/782: 0.0015, acc: 1.0

2026-01-29 13:35:01.140685, epoch: 30, train_loss: 8.3551, train_acc: 1.00, test_loss: 442.0490, test_acc: 0.77
[34m[1mwandb[0m: [33mWARNING[0m Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
--- Logging error ---
