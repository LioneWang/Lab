cuda
{'num_workers': 1, 'pin_memory': True}
/home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:06<00:00, 27.9MB/s]
50000
781
782
10000
312
313
2026-01-29 12:42:04.816690, 200/782: 1.6685, acc: 0.296875
2026-01-29 12:42:13.891039, 400/782: 1.5578, acc: 0.4375
2026-01-29 12:42:22.938348, 600/782: 1.6226, acc: 0.40625
[34m[1mwandb[0m: [33mWARNING[0m Data passed to `wandb.Image` should consist of values in the range [0, 255], image data will be normalized to this range, but behavior will be removed in a future version of wandb.

2026-01-29 12:42:43.027331, epoch: 1, train_loss: 1308.5434, train_acc: 0.38, test_loss: 437.3310, test_acc: 0.48

2026-01-29 12:42:52.266078, 200/782: 1.3743, acc: 0.484375
2026-01-29 12:43:01.401429, 400/782: 1.6547, acc: 0.40625
2026-01-29 12:43:10.502913, 600/782: 1.3734, acc: 0.46875

2026-01-29 12:43:29.678319, epoch: 2, train_loss: 1112.2688, train_acc: 0.48, test_loss: 425.8992, test_acc: 0.51

2026-01-29 12:43:38.795611, 200/782: 1.3534, acc: 0.515625
2026-01-29 12:43:47.833645, 400/782: 1.1396, acc: 0.515625
2026-01-29 12:43:56.874373, 600/782: 0.9176, acc: 0.640625

2026-01-29 12:44:14.761546, epoch: 3, train_loss: 948.5537, train_acc: 0.56, test_loss: 362.1835, test_acc: 0.58

2026-01-29 12:44:23.980504, 200/782: 1.1073, acc: 0.546875
2026-01-29 12:44:33.032852, 400/782: 0.9250, acc: 0.640625
2026-01-29 12:44:42.089874, 600/782: 1.0176, acc: 0.609375

2026-01-29 12:44:59.644552, epoch: 4, train_loss: 854.5058, train_acc: 0.61, test_loss: 343.1667, test_acc: 0.61

2026-01-29 12:45:08.858938, 200/782: 0.8461, acc: 0.78125
2026-01-29 12:45:17.930797, 400/782: 0.8702, acc: 0.6875
2026-01-29 12:45:26.996112, 600/782: 1.1013, acc: 0.625

2026-01-29 12:45:43.811491, epoch: 5, train_loss: 769.9400, train_acc: 0.65, test_loss: 312.7668, test_acc: 0.64

2026-01-29 12:45:53.017404, 200/782: 1.0258, acc: 0.65625
2026-01-29 12:46:02.078273, 400/782: 0.8736, acc: 0.703125
2026-01-29 12:46:11.177019, 600/782: 0.9892, acc: 0.609375

2026-01-29 12:46:27.259109, epoch: 6, train_loss: 696.0497, train_acc: 0.69, test_loss: 285.6094, test_acc: 0.68

2026-01-29 12:46:36.464694, 200/782: 0.8251, acc: 0.65625
2026-01-29 12:46:45.553443, 400/782: 0.7094, acc: 0.796875
2026-01-29 12:46:54.727569, 600/782: 0.7183, acc: 0.765625

2026-01-29 12:47:10.896433, epoch: 7, train_loss: 639.5242, train_acc: 0.71, test_loss: 287.8621, test_acc: 0.68

2026-01-29 12:47:20.106971, 200/782: 0.9644, acc: 0.703125
2026-01-29 12:47:29.289580, 400/782: 0.6673, acc: 0.71875
2026-01-29 12:47:38.393288, 600/782: 0.6876, acc: 0.796875

2026-01-29 12:47:54.626854, epoch: 8, train_loss: 593.3455, train_acc: 0.73, test_loss: 292.6191, test_acc: 0.67

2026-01-29 12:48:03.815749, 200/782: 0.7771, acc: 0.6875
2026-01-29 12:48:12.982156, 400/782: 0.8046, acc: 0.734375
2026-01-29 12:48:22.075027, 600/782: 0.5354, acc: 0.828125

2026-01-29 12:48:37.814836, epoch: 9, train_loss: 539.4356, train_acc: 0.76, test_loss: 240.3640, test_acc: 0.72

2026-01-29 12:48:47.118105, 200/782: 0.5102, acc: 0.796875
2026-01-29 12:48:56.276559, 400/782: 0.9517, acc: 0.703125
2026-01-29 12:49:05.382593, 600/782: 0.6888, acc: 0.734375

2026-01-29 12:49:21.168463, epoch: 10, train_loss: 496.5275, train_acc: 0.77, test_loss: 250.4566, test_acc: 0.72

2026-01-29 12:49:30.481338, 200/782: 0.4806, acc: 0.828125
2026-01-29 12:49:39.605064, 400/782: 0.7158, acc: 0.796875
2026-01-29 12:49:48.685164, 600/782: 0.5329, acc: 0.84375

2026-01-29 12:50:04.564630, epoch: 11, train_loss: 446.9793, train_acc: 0.80, test_loss: 238.6156, test_acc: 0.74

2026-01-29 12:50:13.837876, 200/782: 0.4343, acc: 0.875
2026-01-29 12:50:22.976152, 400/782: 0.6073, acc: 0.796875
2026-01-29 12:50:32.104535, 600/782: 0.5802, acc: 0.8125

2026-01-29 12:50:47.841997, epoch: 12, train_loss: 402.4216, train_acc: 0.82, test_loss: 209.9642, test_acc: 0.77

2026-01-29 12:50:57.129342, 200/782: 0.3323, acc: 0.875
2026-01-29 12:51:06.315998, 400/782: 0.5627, acc: 0.796875
2026-01-29 12:51:15.478736, 600/782: 0.4310, acc: 0.828125

2026-01-29 12:51:31.313736, epoch: 13, train_loss: 368.6590, train_acc: 0.83, test_loss: 227.8818, test_acc: 0.76

2026-01-29 12:51:40.505083, 200/782: 0.6308, acc: 0.734375
2026-01-29 12:51:49.613305, 400/782: 0.2281, acc: 0.890625
2026-01-29 12:51:58.768817, 600/782: 0.3213, acc: 0.90625

2026-01-29 12:52:14.519818, epoch: 14, train_loss: 317.8618, train_acc: 0.86, test_loss: 210.2172, test_acc: 0.78

2026-01-29 12:52:23.743012, 200/782: 0.2570, acc: 0.921875
2026-01-29 12:52:32.928859, 400/782: 0.3183, acc: 0.890625
2026-01-29 12:52:42.087665, 600/782: 0.3285, acc: 0.84375

2026-01-29 12:52:57.903353, epoch: 15, train_loss: 283.2262, train_acc: 0.87, test_loss: 201.1183, test_acc: 0.79

2026-01-29 12:53:07.143670, 200/782: 0.3965, acc: 0.828125
2026-01-29 12:53:16.323130, 400/782: 0.3670, acc: 0.828125
2026-01-29 12:53:25.522761, 600/782: 0.1600, acc: 0.9375

2026-01-29 12:53:41.191692, epoch: 16, train_loss: 244.8916, train_acc: 0.89, test_loss: 224.7779, test_acc: 0.77

2026-01-29 12:53:50.418633, 200/782: 0.3959, acc: 0.859375
2026-01-29 12:53:59.572443, 400/782: 0.1906, acc: 0.90625
2026-01-29 12:54:08.741996, 600/782: 0.3184, acc: 0.84375

2026-01-29 12:54:24.629595, epoch: 17, train_loss: 208.0440, train_acc: 0.91, test_loss: 217.2624, test_acc: 0.78

2026-01-29 12:54:33.869274, 200/782: 0.2397, acc: 0.890625
2026-01-29 12:54:43.094668, 400/782: 0.2344, acc: 0.890625
2026-01-29 12:54:52.202372, 600/782: 0.1972, acc: 0.890625

2026-01-29 12:55:07.852023, epoch: 18, train_loss: 174.5430, train_acc: 0.92, test_loss: 213.5513, test_acc: 0.79

2026-01-29 12:55:17.117082, 200/782: 0.1728, acc: 0.9375
2026-01-29 12:55:26.327708, 400/782: 0.1014, acc: 0.96875
2026-01-29 12:55:35.444720, 600/782: 0.1143, acc: 0.984375

2026-01-29 12:55:51.106812, epoch: 19, train_loss: 136.2779, train_acc: 0.94, test_loss: 295.7952, test_acc: 0.75

2026-01-29 12:56:00.387744, 200/782: 0.1101, acc: 0.984375
2026-01-29 12:56:09.502269, 400/782: 0.1835, acc: 0.90625
2026-01-29 12:56:18.636411, 600/782: 0.1231, acc: 0.921875

2026-01-29 12:56:34.361392, epoch: 20, train_loss: 116.1798, train_acc: 0.95, test_loss: 264.7270, test_acc: 0.76

2026-01-29 12:56:43.678983, 200/782: 0.0779, acc: 0.96875
2026-01-29 12:56:52.777687, 400/782: 0.1649, acc: 0.921875
2026-01-29 12:57:01.932547, 600/782: 0.1381, acc: 0.96875
