{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5738dca-cb13-4762-8364-eb27e00adc6e",
   "metadata": {},
   "source": [
    "- input embedding + encoder + decoder\n",
    "    - position encoding is in input embedding\n",
    "- rnn 天然编码了位置信息\n",
    "    - $h_{t}=f(h_{t-1},x_t)$\n",
    "    - $f$ 是非线性激活函数，$h_{t-1}$ 是前一时间步的隐藏状态，$x_t$ 是当前时间步的输入。由于 $h_t$ 依赖于 $h_{t-1}$，而 $h_{t-1}$ 又依赖于 $h_{t-2}$，以此类推，隐藏状态包含了从初始时间步到当前时间步的所有历史信息。这种递归结构使得位置信息被隐式地编码在隐藏状态中。\n",
    "    - RNN 通过其递归结构隐式地编码位置信息，而 Transformer 需要通过**显式添加位置编码**来获取位置信息。\n",
    "- 如果在 Transformer Encoder 中没有使用位置编码，那么模型将无法区分输入序列中各个词的顺序，这实际上等同于一个词袋（Bag of Words）模型。原因是 Transformer 的**自注意力机制本质上是对输入的加权求和**，而没有位置编码的情况下，模型无法获取任何位置信息。\n",
    "- Permutation Equivariance（排列等变）\n",
    "    - **Permutation Equivariance（排列等变）**：如果对输入序列进行某种排列，模型的输出将以相同的方式被排列。\n",
    "    - Permutation Invariance（排列不变）：对输入序列的排列不会影响模型的输出，即输出与输入的排列无关。\n",
    "    - 没有位置编码的 Transformer Encoder 并不是排列不变的，而是排列等变的。这意味着如果我们改变输入序列中词的顺序，输出序列中的元素也会按照相同的方式重新排列，但输出本身的数值不会保持不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be2eae81-609e-499b-b0d5-2c3d6938b374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16369ec0-4be9-4d87-8d13-80932bf4e6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x77b7bc12a070>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58acbbe3-939d-4000-9d06-72c88084ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型参数\n",
    "vocab_size = 10000  # 词汇表大小\n",
    "d_model = 512       # 嵌入维度\n",
    "nhead = 8           # 注意力头数\n",
    "num_layers = 1      # Transformer Encoder 层数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739b4ed-1e16-4ef9-96ba-f49c14f5f521",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c37c68-78f5-4225-9f6e-5f4061a4d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入序列\n",
    "sequence_length = 5  # 序列长度\n",
    "embedding_dim = 8    # 词嵌入维度\n",
    "batch_size = 1       # 批大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c0aaefb-009b-4f26-bbda-31b8a23be736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_sequence = torch.randn(batch_size, sequence_length, embedding_dim)\n",
    "original_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9681d378-1556-4477-9db4-f33dbbf952a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431,\n",
       "          -1.6047],\n",
       "         [-0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,\n",
       "           0.7624],\n",
       "         [ 1.6423, -0.1596, -0.4974,  0.4396, -0.7581,  1.0783,  0.8008,\n",
       "           1.6806],\n",
       "         [ 0.0349,  0.3211,  1.5736, -0.8455,  1.3123,  0.6872, -1.0892,\n",
       "          -0.3553],\n",
       "         [-1.4181,  0.8963,  0.0499,  2.2667,  1.1790, -0.4345, -1.3864,\n",
       "          -1.2862]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28304290-aaa8-47bb-9f0b-1096b2ea39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建一个打乱顺序的输入序列\n",
    "permuted_sequence = original_sequence.clone()\n",
    "permutation = torch.randperm(sequence_length)\n",
    "permuted_sequence = permuted_sequence[:, permutation, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6ac973f-8211-4619-a80c-b998f28c407c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7df1739-e266-4c79-b5e4-0f262a43ee9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4181,  0.8963,  0.0499,  2.2667,  1.1790, -0.4345, -1.3864,\n",
       "          -1.2862],\n",
       "         [ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431,\n",
       "          -1.6047],\n",
       "         [ 0.0349,  0.3211,  1.5736, -0.8455,  1.3123,  0.6872, -1.0892,\n",
       "          -0.3553],\n",
       "         [ 1.6423, -0.1596, -0.4974,  0.4396, -0.7581,  1.0783,  0.8008,\n",
       "           1.6806],\n",
       "         [-0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,\n",
       "           0.7624]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dc8f6e1-acb4-4a97-9e2b-a5962b86d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f40d20df-bb7e-4172-a166-d8af0a7d855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 16\n",
    "# 超参数\n",
    "rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b1cec94-f0a9-4a77-855d-1f5edfb1f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_output, _ = rnn(original_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2e48152-80c5-4607-8569-728729975819",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_output, _ = rnn(permuted_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9eedb70-67cd-49aa-950e-b74319c197d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 16]), torch.Size([1, 5, 16]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_output.shape, perm_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b20452f-0947-48f3-91fa-4cca570a73de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1647,  0.1817,  0.1086,  0.3989, -0.5853, -0.1526,  0.2821,  0.1751,\n",
       "         0.0053, -0.1486,  0.4298, -0.3109,  0.2444, -0.2696,  0.1174, -0.1964],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global mean pooling\n",
    "ori_output.squeeze(0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "106c7aa3-8db0-4882-8413-93ab0073d04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1541,  0.2012,  0.1875,  0.4956, -0.6121, -0.1516,  0.3347,  0.2138,\n",
       "         0.1248, -0.1832,  0.3795, -0.3336,  0.3319, -0.1917,  0.2129, -0.3236],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_output.squeeze(0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e666d-f2d2-4f24-a8dc-ef1a44f00bfd",
   "metadata": {},
   "source": [
    "**结论**\n",
    "- RNN不具备等变性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961ded5-edd5-49fd-9e1b-e21de3c61a74",
   "metadata": {},
   "source": [
    "### w/o pe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c6412-3a0b-4eb0-95ec-b40a000f8904",
   "metadata": {},
   "source": [
    "```\n",
    "self_attention(perm(x)) = perm(self_attention(x)).\n",
    "```\n",
    "- x: input sequence\n",
    "- perm：permutation，置换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "653d935d-ce2f-4a03-a4a7-2bcc8e266dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义嵌入层和 Transformer Encoder\n",
    "embedding = nn.Embedding(vocab_size, d_model)\n",
    "# dropout == 0.\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=0.0)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "391b09ec-be6a-4b37-be59-a975de22658c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成随机输入序列\n",
    "seq_len = 10  # 序列长度\n",
    "# 生成[0,vocab_size]之间的随机10个数字\n",
    "input_ids = torch.randint(0, vocab_size, (seq_len,))\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9190efc-a6e5-4d60-b214-95fe9d473119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打乱输入序列\n",
    "perm = torch.randperm(seq_len)\n",
    "shuffled_input_ids = input_ids[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a13b0fec-6931-409e-a9b7-8db55541c0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5, 3, 7, 4, 0, 2, 1, 6, 8, 9]),\n",
       " tensor([4, 6, 5, 1, 3, 0, 7, 2, 8, 9]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm, torch.argsort(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05e5bf04-e528-41e5-bb34-f339b4ccc71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512])\n",
      "torch.Size([10, 512])\n"
     ]
    }
   ],
   "source": [
    "# 获取嵌入表示\n",
    "embedded_input = embedding(input_ids)  # [seq_len, d_model]\n",
    "embedded_shuffled_input = embedding(shuffled_input_ids)\n",
    "print(embedded_input.shape)\n",
    "print(embedded_shuffled_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc6fd0b2-39b8-48de-81e3-479b6aa1a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "# Transformer 期望的输入形状为 [seq_len, batch_size, d_model]，因此需要调整维度。\n",
    "\n",
    "# 添加 batch 维度\n",
    "# [seq_len, 1, d_model]\n",
    "embedded_input = embedded_input.unsqueeze(1)       \n",
    "print(embedded_input.shape)\n",
    "embedded_shuffled_input = embedded_shuffled_input.unsqueeze(1)\n",
    "\n",
    "# 通过 Transformer Encoder\n",
    "output = transformer_encoder(embedded_input)           # [seq_len, 1, d_model]\n",
    "output_shuffled = transformer_encoder(embedded_shuffled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5440ebc5-955e-4cd5-b9e4-7b79f9aa7127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1, 512]), torch.Size([10, 1, 512]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, output_shuffled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e1e7271-dbbd-4c48-be9d-ae151b0e5c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(output, output_shuffled, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "17bb8700-e275-4fe5-b248-f4f47072901c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "are_outputs_equal = torch.allclose(output.squeeze(1).mean(dim=0), output_shuffled.squeeze(1).mean(dim=0), atol=1e-6)\n",
    "are_outputs_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c8bf19c-a113-4afe-aed4-2ed55ace57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_perm = torch.argsort(perm)\n",
    "output_shuffled_reordered = output_shuffled[inverse_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77d88145-db1c-4bcb-9626-578dafa591a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(output, output_shuffled_reordered, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2ba4e1-c634-4e1f-84af-62b48b894e24",
   "metadata": {},
   "source": [
    "**结论**\n",
    "- Transformer具备排列等变性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa954b8c-db1a-4e1f-a455-0f9dd3865248",
   "metadata": {},
   "source": [
    "### with pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b461c915-dbee-4229-8952-a3af7439d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        # 创建位置编码矩阵\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 加性位置编码\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6653f89b-7e08-48c4-9c2a-60e71a383122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加位置编码\n",
    "pos_encoder = PositionalEncoding(d_model)\n",
    "embedded_input_pos = pos_encoder(embedded_input)\n",
    "embedded_shuffled_input_pos = pos_encoder(embedded_shuffled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1a552960-1d1a-422c-b16f-d5c79fe680b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过 Transformer Encoder\n",
    "output_pe = transformer_encoder(embedded_input_pos)\n",
    "output_shuffled_pe = transformer_encoder(embedded_shuffled_input_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c09d3ac-27a2-4be2-8cff-30d0c9b3946e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1, 512]), torch.Size([10, 1, 512]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pe.shape, output_shuffled_pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fd3f227-45d3-4326-bcfe-754532fb0867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global mean pooling\n",
    "torch.allclose(output_pe.squeeze(1).mean(dim=0), output_shuffled_pe.squeeze(1).mean(dim=0), atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d912a96-a295-4852-8a66-042058ee18e3",
   "metadata": {},
   "source": [
    "**结论**\n",
    "- 加PE的Transformer不具备排列等变性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93219a05-9006-4d33-bd6c-772b6db5e9b2",
   "metadata": {},
   "source": [
    "### 数学推导：`self_attention(perm(x)) = perm(self_attention(x))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b61b5d7-8128-420c-81d8-5974ddfe484c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T14:46:10.712612Z",
     "iopub.status.busy": "2024-11-02T14:46:10.712140Z",
     "iopub.status.idle": "2024-11-02T14:46:10.726352Z",
     "shell.execute_reply": "2024-11-02T14:46:10.724804Z",
     "shell.execute_reply.started": "2024-11-02T14:46:10.712576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 0, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = torch.tensor([[1, 0, 0, 0],\n",
    "                   [0, 0, 1, 0],\n",
    "                   [0, 1, 0, 0],\n",
    "                   [0, 0, 0, 1]])\n",
    "P @ P.T, P.T @ P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20c90b5-08ef-4c3f-9efa-ebde009aa903",
   "metadata": {},
   "source": [
    "- 设 $P$ 是排列矩阵，排列后的输入为：$X_{\\text{perm}}=PX$\n",
    "- QKV\n",
    "    - $Q_{\\text{perm}}=PQ, K_{\\text{perm}}=PK,V_{\\text{perm}}=PV$\n",
    "- attention score matrix\n",
    "    - $S_{\\text{perm}}=\\frac{Q_{\\text{perm}}K^T_{\\text{perm}}}{\\sqrt{d_k}}=\\frac{PQK^TP^T}{\\sqrt{d_k}}=P\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)P^T=PSP^T$\n",
    "        - $S=\\frac{QK^T}{\\sqrt{d_k}}$\n",
    "- softmax\n",
    "    - $A_{\\text{perm}}=\\text{softmax}(S_{\\text{perm}})=\\text{softmax}(PSP^T)=PAP^T$\n",
    "        - $A=\\text{softmax(S)}$\n",
    "- attention output\n",
    "    - $Y_{\\text{perm}}=A_{\\text{perm}}V_{\\text{perm}}=PAP^TPV=P(AV)$\n",
    "        - 对于排列矩阵 $P^TP=I$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da599bf8-6396-47e8-97db-b77685bbd8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5043, 0.1345, 0.1801, 0.1810],\n",
       "         [0.3099, 0.0326, 0.3377, 0.3198],\n",
       "         [0.2596, 0.2702, 0.1501, 0.3201],\n",
       "         [0.0472, 0.3261, 0.1903, 0.4363]]),\n",
       " tensor([[0.5043, 0.1345, 0.1801, 0.1810],\n",
       "         [0.3099, 0.0326, 0.3377, 0.3198],\n",
       "         [0.2596, 0.2702, 0.1501, 0.3201],\n",
       "         [0.0472, 0.3261, 0.1903, 0.4363]]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "P = torch.tensor([[1, 0, 0, 0],\n",
    "                   [0, 0, 1, 0],\n",
    "                   [0, 1, 0, 0],\n",
    "                   [0, 0, 0, 1]], dtype=torch.float32)\n",
    "S = torch.randn(4, 4)\n",
    "\n",
    "F.softmax(P @ S @ P.T, dim=1), P @ F.softmax(S, dim=1) @ P.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ubuntu-5070Ti",
   "language": "python",
   "name": "rdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
