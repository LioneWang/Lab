{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0e48de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:06:52.154221Z",
     "start_time": "2024-02-19T12:06:52.146740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (0.24.0)\n",
      "Requirement already satisfied: click>=8.0.1 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: eval-type-backport in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (0.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (3.1.46)\n",
      "Requirement already satisfied: packaging in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.15.0 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (6.33.0)\n",
      "Requirement already satisfied: pydantic<3 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (2.32.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (2.51.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from wandb) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jiawei-wang/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb\n",
    "!wandb login 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\n",
    "# ~/.netrc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc437c19-a95a-4491-b2a9-9cf59917571e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T14:08:33.203436Z",
     "iopub.status.busy": "2024-12-17T14:08:33.202778Z",
     "iopub.status.idle": "2024-12-17T14:08:33.225211Z",
     "shell.execute_reply": "2024-12-17T14:08:33.222790Z",
     "shell.execute_reply.started": "2024-12-17T14:08:33.203386Z"
    }
   },
   "source": [
    "```\n",
    "import wandb\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 1000\n",
    "NUM_TOKENS = 10\n",
    "LR = 1e-5\n",
    "KL_FACTOR = 6000\n",
    "WANDB = False\n",
    "\n",
    "if WANDB:\n",
    "    run = wandb.init(\n",
    "        project=\"tinycatstories\",\n",
    "        config={\n",
    "            \"epochs\": NUM_EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"num_tokens\": NUM_TOKENS,\n",
    "            \"learning_rate\": LR,\n",
    "            \"kl_factor\": KL_FACTOR,\n",
    "        },\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15111c13",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d730cc5-2000-4377-b9ac-c3da1ee69e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "print(wandb.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4c9871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:01:39.919238Z",
     "start_time": "2023-04-23T14:01:38.315799Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random # to set the python random seed\n",
    "import numpy # to set the numpy random seed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "from datetime import datetime\n",
    "# Ignore excessive warnings\n",
    "import logging\n",
    "logging.propagate = False \n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# WandB – Import the wandb library\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbfacf7",
   "metadata": {},
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b070f6",
   "metadata": {},
   "source": [
    "```\n",
    "!pip install wandb\n",
    "wandb login\n",
    "# api_key\n",
    "~/.netrc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d250d6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T12:20:22.753328Z",
     "start_time": "2023-04-23T12:20:22.747238Z"
    }
   },
   "source": [
    "- WandB: weights & biases\n",
    "\n",
    "```\n",
    "wandb.init(project=\"wandb-demo-0423\")\n",
    "# 字典（dict）\n",
    "config = wandb.config\n",
    "config[k] = v\n",
    "\n",
    "# 实例化模型\n",
    "model = Net().to(device)\n",
    "train_dataset\n",
    "test_dataset\n",
    "train_dataloader\n",
    "test_dataloader\n",
    "\n",
    "# 监控模型，histogram weights and biases\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_acc = train(model, train_dataloader)\n",
    "    # 字典的形式\n",
    "    wandb.log({\"train_loss\": train_loss, \"train_acc\": train_acc})\n",
    "    # 评估，不进行参数的更新\n",
    "    test_loss, test_acc = test(model, test_dataloader)\n",
    "    wandb.log({\"test_loss\": test_loss, \"test_acc\": train_acc})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda83126",
   "metadata": {},
   "source": [
    "## model, train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d1c2f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:01:46.208111Z",
     "start_time": "2023-04-23T14:01:46.203295Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, criterion, optimizer, device):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_batch = len(train_dataloader)\n",
    "    for batch_idx, (images, labels) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "\n",
    "        # 标准的处理，用 validate data；这个过程是监督训练过程，用于 early stop\n",
    "        n_corrects = (out.argmax(axis=1) == labels).sum().item()\n",
    "        acc = n_corrects/labels.size(0)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()   # 更细 模型参数\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += n_corrects\n",
    "        \n",
    "        if (batch_idx+1) % 200 == 0:\n",
    "            print(f'{datetime.now()}, {batch_idx+1}/{total_batch}: {loss.item():.4f}, acc: {acc}')\n",
    "    total_errors = len(train_dataloader.dataset) - total_correct\n",
    "    return total_loss, total_correct/len(train_dataloader.dataset), total_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7f0cdfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:03.797083Z",
     "start_time": "2023-04-23T14:02:03.784871Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(test_dataloader, model, criterion, device, classes):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    example_images = []\n",
    "    model.eval()\n",
    "    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1).to(device)\n",
    "    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1).to(device)\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        \n",
    "        mis_preds_indice = torch.flatten((preds != labels).nonzero())\n",
    "        mis_preds = preds[mis_preds_indice]\n",
    "        mis_labels = labels[mis_preds_indice]\n",
    "        mis_images = images[mis_preds_indice]\n",
    "        \n",
    "        # 13*8 + 4 == 108\n",
    "        for idx in range(len(mis_preds)):\n",
    "            if len(example_images) < 32: \n",
    "                        \n",
    "                        # --- 关键修改：反归一化 ---\n",
    "                        img = images[idx] * std + mean # 变回 [0, 1] 范围\n",
    "                        img = img.clamp(0, 1)          # 强制截断，防止溢出导致的噪点\n",
    "                        \n",
    "                        # --- 关键修改：维度转换 (C, H, W) -> (H, W, C) ---\n",
    "                        img_np = img.cpu().numpy().transpose(1, 2, 0)\n",
    "                        \n",
    "                        # 3. 转换为 uint8 [0, 255]（这是最保险的格式）\n",
    "                        img_uint8 = (img_np * 255).astype(np.uint8)\n",
    "                        \n",
    "                        example_images.append(wandb.Image(\n",
    "                            img_uint8, \n",
    "                            caption=f\"Pred: {classes[preds[idx]]}, Truth: {classes[labels[idx]]}\"\n",
    "                        ))\n",
    "            else:\n",
    "                break\n",
    "    total_errors = len(test_loader.dataset) - total_correct\n",
    "    return example_images, total_loss, total_correct / len(test_loader.dataset), total_errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e4bf47",
   "metadata": {},
   "source": [
    "## wandb config & dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20354ff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:15.849162Z",
     "start_time": "2023-04-23T14:02:05.682841Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/jiawei-wang/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjw4807\u001b[0m (\u001b[33mlione-wang\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jiawei-wang/workspace/Lab/DL/wandb/run-20260129_130650-z7mn4jfu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lione-wang/Lab-DL/runs/z7mn4jfu' target=\"_blank\">vital-planet-5</a></strong> to <a href='https://wandb.ai/lione-wang/Lab-DL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lione-wang/Lab-DL' target=\"_blank\">https://wandb.ai/lione-wang/Lab-DL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lione-wang/Lab-DL/runs/z7mn4jfu' target=\"_blank\">https://wandb.ai/lione-wang/Lab-DL/runs/z7mn4jfu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"WANDB_API_KEY\"] = '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'\n",
    "os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "\n",
    "# WandB – Initialize a new run\n",
    "# 一个 project 可以 run 多次\n",
    "wandb.init(project=\"Lab-DL\")\n",
    "wandb.watch_called = False # Re-run the model without restarting the runtime, unnecessary after our next release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d130c023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:17.680506Z",
     "start_time": "2023-04-23T14:02:17.673655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty dict\n",
    "wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac35385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:18.655123Z",
     "start_time": "2023-04-23T14:02:18.641752Z"
    }
   },
   "outputs": [],
   "source": [
    "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
    "config = wandb.config          # Initialize config\n",
    "config.batch_size = 64          # input batch size for training (default: 64)\n",
    "config.test_batch_size = 32    # input batch size for testing (default: 1000)\n",
    "config.epochs = 30             # number of epochs to train (default: 10)\n",
    "config.lr = 1e-3              # learning rate (default: 0.01)\n",
    "config.momentum = 0.9         # SGD momentum (default: 0.5) \n",
    "config.weight_decay = 5e-4\n",
    "config.no_cuda = False         # disables CUDA training\n",
    "config.seed = 42               # random seed (default: 42)\n",
    "config.log_interval = 10     # how many batches to wait before logging training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30148831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:10:30.432096Z",
     "start_time": "2023-04-23T15:10:30.423172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "{'num_workers': 1, 'pin_memory': True}\n"
     ]
    }
   ],
   "source": [
    "use_cuda = not config.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c289c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:24.799152Z",
     "start_time": "2023-04-23T14:02:22.592645Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jiawei-wang/miniconda3/envs/rdl/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bba03e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:02:26.754527Z",
     "start_time": "2023-04-23T14:02:24.801556Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "    \n",
    "# Now we load our training and test datasets and apply the transformations defined above\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                 download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=config.batch_size,\n",
    "                                           shuffle=True, \n",
    "                                           **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size=config.test_batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          **kwargs)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "635db4d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:11:21.290317Z",
     "start_time": "2023-04-23T15:11:21.283595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "781\n",
      "782\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(train_dataset)//config.batch_size)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c2e26f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:11:50.081828Z",
     "start_time": "2023-04-23T15:11:50.069920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "312\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataset))\n",
    "print(len(test_dataset)//config.test_batch_size)\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba878c",
   "metadata": {},
   "source": [
    "## training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99a696a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:52:50.016509Z",
     "start_time": "2023-04-23T14:02:30.904713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-29 13:09:39.132841, 200/782: 1.4635, acc: 0.546875\n",
      "2026-01-29 13:09:48.546310, 400/782: 1.4243, acc: 0.46875\n",
      "2026-01-29 13:09:57.727774, 600/782: 1.4737, acc: 0.5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#字典的形式放在wandb的log里\u001b[39;00m\n\u001b[1;32m     18\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_acc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_errors})\n\u001b[0;32m---> 19\u001b[0m example_images, test_loss, test_acc, test_errors \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample_images\u001b[39m\u001b[38;5;124m'\u001b[39m: example_images, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: test_loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: test_acc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_errors\u001b[39m\u001b[38;5;124m'\u001b[39m: test_errors})\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[17], line 25\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(test_dataloader, model, criterion, device, classes)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mis_preds)):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(example_images) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m32\u001b[39m: \n\u001b[1;32m     23\u001b[0m                 \n\u001b[1;32m     24\u001b[0m                 \u001b[38;5;66;03m# --- 关键修改：反归一化 ---\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m                 img \u001b[38;5;241m=\u001b[39m images[idx] \u001b[38;5;241m*\u001b[39m \u001b[43mstd\u001b[49m \u001b[38;5;241m+\u001b[39m mean \u001b[38;5;66;03m# 变回 [0, 1] 范围\u001b[39;00m\n\u001b[1;32m     26\u001b[0m                 img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)          \u001b[38;5;66;03m# 强制截断，防止溢出导致的噪点\u001b[39;00m\n\u001b[1;32m     28\u001b[0m                 \u001b[38;5;66;03m# --- 关键修改：维度转换 (C, H, W) -> (H, W, C) ---\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'std' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set random seeds and deterministic pytorch for reproducibility\n",
    "# random.seed(config.seed)      \n",
    "torch.manual_seed(config.seed) \n",
    "# numpy.random.seed(config.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Load the dataset: We're training our CNN on CIFAR10 (https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# WandB – wandb.watch() automatically fetches all layer dimensions, gradients, model parameters and logs them automatically to your dashboard.\n",
    "# Using log=\"all\" log histograms of parameter values in addition to gradients\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "for epoch in range(1, config.epochs + 1):\n",
    "    train_loss, train_acc, train_errors = train(train_loader, model, criterion, optimizer, device)\n",
    "    #字典的形式放在wandb的log里\n",
    "    wandb.log({\"train_loss\": train_loss, \"train_acc\": train_acc, \"train_errors\": train_errors})\n",
    "    example_images, test_loss, test_acc, test_errors = test(test_loader, model, criterion, device, classes)\n",
    "    wandb.log({'example_images': example_images, 'test_loss': test_loss, 'test_acc': test_acc, 'test_errors': test_errors})\n",
    "    print()\n",
    "    print(f'{datetime.now()}, epoch: {epoch}, train_loss: {train_loss:.4f}, train_acc: {train_acc:.2f}, test_loss: {test_loss:.4f}, test_acc: {test_acc:.2f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f99ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB – Save the model checkpoint. This automatically saves a file to the cloud and associates it with the current run.\n",
    "torch.save(model.state_dict(), \"model.ckpt\")\n",
    "wandb.save('model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ubuntu-5070Ti",
   "language": "python",
   "name": "rdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
